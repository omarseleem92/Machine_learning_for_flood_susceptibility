{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "import os\n",
    "import cv2\n",
    "import keras \n",
    "from keras.utils import normalize\n",
    "from keras import *\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the points and convert it to polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the area which we need to map its flood susceptibility as a point\n",
    "# We are just repeating the same steps as reading the training data\n",
    "points=gpd.read_file('Points.shp')\n",
    "points.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points['index_ID']=points.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_dist=115 #buffer distance = image size x spatial resolution /2\n",
    "\n",
    "# Read in the shapefile\n",
    "points = gpd.read_file(\"Points.shp\")\n",
    "\n",
    "# Create square buffers with a side length of buffer_dist units around the point features\n",
    "points['geometry'] = points.buffer(buffer_dist)\n",
    "\n",
    "points['geometry'] = points.geometry.envelope\n",
    "\n",
    "# Save the new shapefile\n",
    "#points.to_file(\"squares.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each feature in the shapefile\n",
    "for index, feature in points.iterrows():\n",
    "    # Create a new GeoDataFrame with just the current feature\n",
    "    #print(index)\n",
    "    \n",
    "    feature_gdf = points.iloc[[index]]\n",
    "    #print(feature_gdf)\n",
    "    #print(feature_gdf['Label'][index])\n",
    "    \n",
    "    \n",
    "        \n",
    "    # Save the feature to a new shapefile\n",
    "    feature_gdf.to_file(r\"D:\\USER\\seleem\\Omar_CNN\\Tag_der_hydrologie\\Git_hub\\divided_mapping\\feature_{}.shp\".format(index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Open the predictive feaure raster and create images for each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raster files with GDAL\n",
    "# import \n",
    "ds = gdal.Open(\"Composite_raster.tif\") # open a raster with several bands, each band  represent one predictive feature\n",
    "gt= ds.GetGeoTransform() #get the transformation data\n",
    "proj = ds.GetProjection() #get the projection\n",
    "\n",
    "band = ds.GetRasterBand(1) #read the first band \n",
    "array = band.ReadAsArray() #read the first band as an array\n",
    "\n",
    "plt.figure()  #plot the raster to check that you every thing is working well\n",
    "plt.imshow(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the path to the folder where we saved the splitted polygons\n",
    "shp_path=r\"D:\\USER\\seleem\\Omar_CNN\\Tag_der_hydrologie\\Git_hub\\divided_mapping\"\n",
    "os.chdir(shp_path)\n",
    "shp_file = glob.glob('*.shp')\n",
    "#index =0\n",
    "for file in shp_file:\n",
    "        #print(str(file))         \n",
    "        ds2 = ogr.Open(file, 1)\n",
    "        layer = ds2.GetLayer()\n",
    "        shp_ds=gpd.read_file(file)\n",
    "        #print(shp_ds['Label'][0])\n",
    "        #index+=1\n",
    "        # we will clip the raster with each polygon and save the flooded and notflooded locations in different folders\n",
    "        # we will check the label, if label =0 then this is not flooded location\n",
    "        #if shp_ds['Label'][0] == 0 : # clip and save not flooded locations\n",
    "             #Save the feature to a new shapefile\n",
    "            #dsClip = gdal.Warp(r\"D:\\USER\\seleem\\Omar_CNN\\Tag_der_hydrologie\\Git_hub\\Predictive_features\\NotFlooded\\feature_\"+str(file[:-4])+\".tif\", ds, cutlineDSName = file,\n",
    "                       #cropToCutline = True, dstNodata = np.nan)\n",
    "        #else: # clip and save flooded locations\n",
    "            # Save the feature to a new shapefile\n",
    "                  \n",
    "        dsClip = gdal.Warp(r\"D:\\USER\\seleem\\Omar_CNN\\Tag_der_hydrologie\\Git_hub\\Mapping\"+str(file[:-4])+\".tif\", ds, cutlineDSName = file,\n",
    "                       cropToCutline = True, dstNodata = np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=r\"D:\\USER\\seleem\\Omar_CNN\\Tag_der_hydrologie\\Git_hub\\Mapping\" # created in data_preperation script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the DEM and save it in a list\n",
    "\n",
    "DEM=[]\n",
    "Slope=[]\n",
    "TWI=[]\n",
    "DTRoad=[]\n",
    "DTRiver=[]\n",
    "CN=[]\n",
    "Rain=[]\n",
    "Aspect=[]\n",
    "Curve=[]\n",
    "Freq=[]\n",
    "DTDrainage=[]\n",
    "name=[]\n",
    "# we have 11 predictive features \n",
    "# every feature is presented in one band \n",
    "# loop over the predictive features\n",
    "predictive_features=[DEM, Slope, TWI, DTRoad, DTRiver, CN, Rain, Aspect, Curve, Freq, DTDrainage] # the features muss be in the same order as the bands in the composite raster\n",
    "\n",
    "print(len(predictive_features))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_data():\n",
    "    for i in range(len(predictive_features)):\n",
    "        print(i+1)\n",
    "        #for category in CATEGORIES:\n",
    "        path= os.path.join(data_path) # Path to flooded and NotFlooded dir\n",
    "        #class_num= CATEGORIES.index(category)\n",
    "            for img in os.listdir(path):\n",
    "                try:\n",
    "                    img_open=rasterio.open(os.path.join(path,img))\n",
    "                    #print(category,img,class_num)\n",
    "                    img_array=img_open.read(i+1)\n",
    "                    #img_array= np.where(img_array < 0, np.nan,img_array)\n",
    "                    #mean=np.nanmean(img_array)\n",
    "                    #img_array= np.where(np.isnan(img_array), mean,img_array)\n",
    "                    #new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                    predictive_features[i].append(img_array)\n",
    "                    \n",
    "                    if i==0:\n",
    "                        name.append(img)\n",
    "                        #print(class_num)\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the predictive feature lists to numpy arrays\n",
    "DEM_array=np.array(DEM).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "Slope_array=np.array(Slope).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "TWI_array=np.array(TWI).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "DTRoad_array=np.array(DTRoad).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "DTRiver_array=np.array(DTRiver).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "CN_array=np.array(CN).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "DTDrainage_array=np.array(DTDrainage).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "Aspect_array=np.array(Aspect).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "Curvature_array=np.array(Curve).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "Freq_Curve_array=np.array(Freq).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "Rain_array=np.array(Rain).reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate all the predicvtive feature arrays into one array\n",
    "X_array=np.concatenate([DEM_array,Slope_array,TWI_array,DTRoad_array, DTRiver_array,CN_array,Rain_array,Aspect_array, Curvature_array, Freq_Curve_array, DTDrainage_array], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('LeNet_11_inputs_23_imgsize_normalized_input_rasters_python.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_predict=model.predict(X_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict=pd.DataFrame()\n",
    "df_predict['FSM']=Y_predict\n",
    "df_predict['name']=name\n",
    "df_predict['index_ID']=df_predict.name.str[8:-4].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSM_df=pd.merge(points,df_predict,on=\"index_ID\")\n",
    "FSM_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSM_df.to_file(\"FSM.shp\") # convert it to a raster in QGIS or arcmap or in python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the point shapefile to raster.\n",
    "# We will use the model prediction (column FSM in df_SA to make a raster)\n",
    "from geocube.api.core import make_geocube\n",
    "import rasterio as rio\n",
    "\n",
    "out_grid= make_geocube(vector_data=FSM_df, measurements=[\"FSM\"], resolution=(-1, 1)) #for most crs negative comes first in resolution\n",
    "out_grid[\"FSM\"].rio.to_raster(\"Flood_susceptibility.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
